{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3xWYj1/0TTopZxYHNtlNt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simon-m-mudd/physical_geography_practicals/blob/main/physical_geography_flood_practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Physical Geography practical 1: Analysis of flood data (and your first look at python)"
      ],
      "metadata": {
        "id": "w0B5VjybE4cI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Written by Simon M Mudd, last update 31-Jan-2024"
      ],
      "metadata": {
        "id": "QITbxPujE6Lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "cpYWtFdtFBVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practical we will work with some data that comes from the National River Flow Archive (NFRA) which can be found at: https://nrfa.ceh.ac.uk/\n",
        "\n",
        "The practical shows you how to perform flood frequency analysis, and then look at the results.\n",
        "\n",
        "It will also give you a basic overview of python. We will use this again later in the course."
      ],
      "metadata": {
        "id": "aFkIvNUjFDLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is this notebook?"
      ],
      "metadata": {
        "id": "IOris4CXG6JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are reading this practical in something called an ipython notebook. The \"i\" is for \"interactive\", the \"python\" is a programming language.\n",
        "\n",
        "If you are doing a degree in the School of GeoSciences at the University of Edinburgh, you will take some classes about the python programming language. This is not one of those courses.\n",
        "\n",
        "In this course I just want you to look at data. In the past we have used spreadsheet programs (i.e., excel) for this. But graphs made here look better, and these notebooks are more flexible."
      ],
      "metadata": {
        "id": "c4YJVyWXHWGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The only thing you need to know about python programming at this stage"
      ],
      "metadata": {
        "id": "h5UujJxpMaql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is organised into \"cells\".\n",
        "\n",
        "* Some of the cells just contain text.\n",
        "* Some contain python code that does something\n",
        "\n",
        "You don't change the text cells.\n",
        "For the python cells you just make them run.\n",
        "\n",
        "**In Noteable** python cells have **In []:** written next to them.\n",
        "\n",
        "**In Google colab** python cells have a symbol that looks like a \"play\" button if you hover over them.\n",
        "\n",
        "In both of these environments, if you click on the cell and then type `shift+enter` the cell will run.\n"
      ],
      "metadata": {
        "id": "16jumRrcMgCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"You just ran some python code! You can now put `Data Scientist` into you Linkedin profile!\")"
      ],
      "metadata": {
        "id": "xUpQXq0-MZyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## On to the practial!"
      ],
      "metadata": {
        "id": "nxfk5q_c5d2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is the NRFA"
      ],
      "metadata": {
        "id": "-VuHL7EX75Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read the website: https://nrfa.ceh.ac.uk/\n",
        "\n",
        "But the NRFA contains data from gauging stations distributed around the UK. A gauging station is a place where hydrologists measure flow. Usually they do some very labour intensive measurements of discharge (that is, the volume of water per unit of time, usually reported in m$^3$/s), and then relate this to the \"stage\" of the river (that is, the elevation of the water surface).\n",
        "\n",
        "The relationship between the stage and the discharge is called a **rating curve**. Hydrolgists make rating curves because stage is much easier to measure than discharge.\n",
        "\n",
        "You can find out the data about the gauging stations in the NRFA catalogue. But for now all you need to know is each station has a **station ID**, which is just a number.\n",
        "\n",
        "For example, station 8010 is the River Spey at Grantown"
      ],
      "metadata": {
        "id": "MrPRKtC078K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get some data from the NFRA!"
      ],
      "metadata": {
        "id": "Vsq0VIYi5pO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets get some data from the National River Flow archive (NRFA).\n",
        "\n",
        "We use a little python tool for this (you need to be connected to the internet).\n",
        "\n",
        "The next bit of code installs the tool. Run the next cell."
      ],
      "metadata": {
        "id": "J0CdN_7E5-LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nrfapy &> /dev/null"
      ],
      "metadata": {
        "id": "B-Yy5njh5IMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets get some data.\n",
        "\n",
        "We are going to get the annual maximum flow. This is the peak discharge at the station for that water year. The standard UK water-year begins on 1st October: for example the 1999 water year begins on 1/10/1999 and ends on 30/9/2000. Choosing the end of September as the end of the water year avoids splitting the data series at a flood-prone time of year.\n",
        "\n",
        "In the following example I am getting the station number 8010 (see above) and I am getting the `amax-flow` data, which is the annual maximum flow. There are other options but you don't need to worry about them."
      ],
      "metadata": {
        "id": "yEKLGn9cZG0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nrfapy\n",
        "\n",
        "station = 8010\n",
        "data_type = \"amax-flow\"\n",
        "amax_flow_df = nrfapy.get_ts(station,data_type)\n",
        "amax_flow_df.head()"
      ],
      "metadata": {
        "id": "AiClY_bNZTIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to develop some physical intuition about discharge: a lowland river might flow 1 metre per second at low flows, and you might get over 3 m/s during a flood. The station on this part to the Spey is 60m wide. For a discharge of 300 m$^3$/s, a velocity of 3m/s, and a width of 60m, you would get a water depth of 1.66m. We can look at the stage measurement (how deep the river is during the flood) to check our estimates:"
      ],
      "metadata": {
        "id": "2tHETjXrU1WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_type = \"amax-stage\"\n",
        "amax_stage_df = nrfapy.get_ts(station,data_type)\n",
        "amax_stage_df.head()"
      ],
      "metadata": {
        "id": "eV_qsb74WK-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey, not bad!\n",
        "\n",
        "We can also plot the maximum disharge from each year's flood.\n",
        "\n",
        "Again, you don't need to change anything below, just click on the cells and type shift+enter to run them."
      ],
      "metadata": {
        "id": "MGUyGvhbWkA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert 'datetime' column to datetime format\n",
        "amax_flow_df['datetime'] = pd.to_datetime(amax_flow_df['time'], format='%Y-%m-%dT%H:%M:%S')\n",
        "\n",
        "\n",
        "# Extract the year from the datetime column\n",
        "amax_flow_df['year'] = amax_flow_df['datetime'].dt.year\n",
        "\n",
        "amax_flow_df.head()"
      ],
      "metadata": {
        "id": "EKano1PDaZ1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a bar plot\n",
        "ax = amax_flow_df.plot.bar(x='year', y='amax-flow', rot=90, figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label to be the year\n",
        "plt.xlabel('Year')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Maximum annual flood for station number: '+str(station))\n",
        "\n",
        "# Show every 3rd label on the x-axis\n",
        "plt.xticks(amax_flow_df[\"amax-flow\"].index[::3]);"
      ],
      "metadata": {
        "id": "kHna9IynacLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now for flood frequency"
      ],
      "metadata": {
        "id": "8rLk38T0dCCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to look at the flood frequency.\n",
        "\n",
        "Before we do the formal flood frequency analysis we will calculate some simple statistics of the floods. First lets look at the probability of annual maximum discharges.\n",
        "\n",
        "We do this using something called a kernal density estimation, which is a method to estimate the probability density of a dataset."
      ],
      "metadata": {
        "id": "ma2NP4WxdF09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = amax_flow_df['amax-flow'].plot.kde(bw_method=1)\n",
        "\n",
        "# Set x-axis label to be the year\n",
        "plt.xlabel('Discharge (m$^3$/s)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Probability density of annual maximum discharge (in m$^3$/s) for station number: '+str(station))"
      ],
      "metadata": {
        "id": "ip6HWFbHXSY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get the average and median values"
      ],
      "metadata": {
        "id": "vs9QqoiOYWnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_amax_Q = amax_flow_df['amax-flow'].mean()\n",
        "median_amax_Q = amax_flow_df['amax-flow'].median()\n",
        "print(\"The mean annual maximum flow is: \" +str(mean_amax_Q) + \" m^3/s and the median is: \" + str(median_amax_Q)+ \" m^3/s\")"
      ],
      "metadata": {
        "id": "DQ1CdBdRYpFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do flood frequency analysis, we need to rank the floods, with the largest flood ranked 1, the second largest 2, and so on. There is a `pandas` script for that:"
      ],
      "metadata": {
        "id": "s133rfs7amuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amax_flow_df['rank_column'] = amax_flow_df['amax-flow'].rank(ascending=False).astype(int)\n",
        "amax_flow_df.head(10)"
      ],
      "metadata": {
        "id": "jyRCHeTfZ5Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to know how many records there are, the ode for that is below."
      ],
      "metadata": {
        "id": "kmaLYAGga1V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_records = len(amax_flow_df['amax-flow'])\n",
        "print(\"The number of years on record is: \"+str(n_records))\n"
      ],
      "metadata": {
        "id": "Qoa27c9xbJ1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating return period"
      ],
      "metadata": {
        "id": "1azp3ThsbfKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The return period, *R*, is calculated using the following equation:\n",
        "\n",
        "$R = \\frac{n+1}{n}$\n",
        "\n",
        "where *R* is the return period (in years), *n* is the number of years on record, and *m* is the rank of the flood in the *n* year record.\n",
        "\n",
        "So we need to divide (*n*+1) (for station 8010 this is 71) by each year's rank, which again is quite easy using `pandas`:"
      ],
      "metadata": {
        "id": "w__b9YXjbi9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amax_flow_df['return_period'] = (n_records+1)/amax_flow_df['rank_column']\n",
        "amax_flow_df.head(10)"
      ],
      "metadata": {
        "id": "A1IcnysUb7Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make a flood frequency plot"
      ],
      "metadata": {
        "id": "h0RhsG8seJ7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now plot the return period against the discharge:"
      ],
      "metadata": {
        "id": "usOP10zgeTtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a bar plot\n",
        "ax = amax_flow_df.plot.scatter(x='return_period', y='amax-flow', figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label to be the year\n",
        "plt.xlabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Return period (yrs)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Return periods for station number: '+str(station))\n"
      ],
      "metadata": {
        "id": "RUHm6y1eecgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This actually looks better if you set the x axis to be in logarithmic scale."
      ],
      "metadata": {
        "id": "AOZzDRfufKPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a bar plot\n",
        "ax = amax_flow_df.plot.scatter(x='return_period', y='amax-flow', figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label to be the year\n",
        "plt.xlabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Return period (yrs)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Return periods for station number: '+str(station))\n",
        "\n",
        "# Set x-axis to logarithmic scale\n",
        "ax.set_xscale('log')"
      ],
      "metadata": {
        "id": "Hvd2jBkZfPhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can fit that data with an equation of the form:\n",
        "\n",
        "$Q_{flood} = a \\ln (R)+b$\n",
        "\n",
        "where ln is the natural logarithm and a and b are some constants you fit.\n",
        "\n",
        "We can do that in `pandas` and by using some python statistics tools."
      ],
      "metadata": {
        "id": "VxHhKht_gORz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a scatter plot\n",
        "ax = amax_flow_df.plot.scatter(x='return_period', y='amax-flow', figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Return period (yrs)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Return periods for station number: '+str(station))\n",
        "\n",
        "# Set x-axis to logarithmic scale\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Perform a linear regression on the natural log of the x data\n",
        "slope, intercept, r_value, p_value, std_err = linregress(np.log(amax_flow_df['return_period']), amax_flow_df['amax-flow'])\n",
        "\n",
        "# Create a range of x values for the fitted line\n",
        "x_fit = np.linspace(min(amax_flow_df['return_period']), max(amax_flow_df['return_period']), num=500)\n",
        "\n",
        "# Calculate the corresponding y values for the fitted line\n",
        "y_fit = slope * np.log(x_fit) + intercept\n",
        "\n",
        "# Plot the fitted line\n",
        "plt.plot(x_fit, y_fit, 'r', label=f'fit: y = {slope:.2f} * ln(x) + {intercept:.2f}')\n",
        "\n",
        "# Show the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "P1v9iXvaf_e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point you may be looking at this code and wondering \"how on Earth will I be able to remember all these python things?\"\n",
        "\n",
        "The author of this notebook is not bad at python but as recently as 2022 would need to spend some time refreshing his memory on Stackoverflow. But now we have AI: I just had the code from the previous cell and asked Microsoft Bard this question:\n",
        "\n",
        "*How do I add a trendline to that plot. I want to fit it with a natural log regression?*\n",
        "\n",
        "Unless you are doing something quite niche, AI can write functional python code for basic data analysis."
      ],
      "metadata": {
        "id": "9AN1cBaJhdZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Find the return period of the mean annual flood"
      ],
      "metadata": {
        "id": "s55yBgNvh9Aw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, lets get the return period of the mean annual flood. The mean annual flood is specifically the mean value of all the amax-flow data, which you calculated earlier. We can calulate it by reorganising the regression equation:\n",
        "\n",
        "\n",
        "$\\frac{Q_{flood}-b}{a} = \\ln (R)$\n",
        "\n",
        "which with some more algebra is\n",
        "$R = exp[ \\frac{Q_{flood}-b}{a}]$"
      ],
      "metadata": {
        "id": "cWKDWoG7iAbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R_maf = np.exp( (mean_amax_Q - intercept) / slope)\n",
        "print(\"The return period of the mean annual flood is: \"+str(R_maf))"
      ],
      "metadata": {
        "id": "kYlyfbB7i2Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can also predict much bigger floods, by taking that original equation:\n",
        "\n",
        "$Q_{flood} = a \\ln (R)+b$\n",
        "\n",
        "and plugging in big return periods. Lets see how big a 500 year flood is:"
      ],
      "metadata": {
        "id": "f83ACjfNjTQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "big_return_period = 500\n",
        "flood_big = slope*np.log(big_return_period)+ intercept\n",
        "print(\"The discharge of a flood with a return period of \"+str(big_return_period)+ \" years is \"+str(flood_big) + \"m^3/s\")"
      ],
      "metadata": {
        "id": "mNXyoIq7jipK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting information about the stations"
      ],
      "metadata": {
        "id": "IbNdOI0092h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have looked at a single station (station number 8010, the River Spey at Grantown). You might want to search for stations on your favourite river. For this we need to look at the NRFA catalogue.\n",
        "\n",
        "We can get this with a line of python: `stations_data = nrfapy.catalogue()`\n",
        "\n",
        "After that we use `pandas` to search the data. The `head()` command below shows you the first few lines of the data and what the column names are."
      ],
      "metadata": {
        "id": "1yWFhjb_95Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nrfapy\n",
        "stations_data = nrfapy.catalogue()\n",
        "stations_data.head()"
      ],
      "metadata": {
        "id": "KslZwSVf6gaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can search for an individual station by using the line below.\n",
        "\n",
        "Try to change the number from 8010.\n",
        "\n",
        "If you use a number that does not correspond to a station you will get an empty row.\n",
        "\n",
        "**Do not change anything else in the code cell!**"
      ],
      "metadata": {
        "id": "DhzKO1j0-f8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stations_data.loc[stations_data['id'] == 8010]"
      ],
      "metadata": {
        "id": "IbBp81Zv6qLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can then use the below query to get all the stations on your favourite river.\n",
        "\n",
        "Try changing the name of the river!"
      ],
      "metadata": {
        "id": "9-gYuYCq-4SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stations_data[stations_data['river'].str.contains(\"Spey\")]"
      ],
      "metadata": {
        "id": "a0EbNc9X7HUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot station locations"
      ],
      "metadata": {
        "id": "8Z_f_B9zYDT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We might want to see where these stations are.\n",
        "\n",
        "We can plot them on a map, but first we need to install something called contextily, which is a nice package for showing basemaps. You don't need to worry about that at this point."
      ],
      "metadata": {
        "id": "6-SBgyh__taC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contextily &> /dev/null"
      ],
      "metadata": {
        "id": "LGLIMQqB_zJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import contextily as ctx\n",
        "\n",
        "# Make a dataframe with just the stations on the Spey.\n",
        "my_stations = stations_data[stations_data['river'].str.contains(\"Spey\")]\n",
        "\n",
        "# Now we use the British National Grid coordinates\n",
        "# Every coordinate reference system (crs) has a code. The british national grid's code is EPSG:27700\n",
        "gdf2 = gpd.GeoDataFrame(my_stations, geometry=gpd.points_from_xy(my_stations.easting, my_stations.northing), crs='EPSG:27700')\n",
        "\n",
        "# You could also do this with latitude and longitude, but it results in a slightly distorted map\n",
        "#gdf = gpd.GeoDataFrame(my_stations, geometry=gpd.points_from_xy(my_stations.longitude, my_stations.latitude), crs='EPSG:4326')\n"
      ],
      "metadata": {
        "id": "QdlejFtUAnCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a plot using geopands\n",
        "ax = gdf2.plot(marker='o', color='red', markersize=20, figsize=(9, 9))\n",
        "\n",
        "\n",
        "# This labels the stations\n",
        "for x, y, label in zip(gdf2.geometry.x, gdf2.geometry.y, gdf2.name):\n",
        "    ax.annotate(label, xy=(x, y), xytext=(3, 3), textcoords=\"offset points\")\n",
        "\n",
        "# The plot looks better if you pad the points by 30km\n",
        "# The next three lines to that. If you want to change the padding only change\n",
        "# the \"padding\" number\n",
        "padding = 30000\n",
        "xlim = (gdf2.total_bounds[0] - padding, gdf2.total_bounds[2] + padding)\n",
        "ylim = (gdf2.total_bounds[1] - padding, gdf2.total_bounds[3] + padding)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "\n",
        "# Now add a basemap\n",
        "ctx.add_basemap(ax,source=ctx.providers.OpenStreetMap.Mapnik,crs=gdf2.crs.to_string())\n",
        "\n",
        "# Set axis labels and title\n",
        "ax.set_xlabel('Easting (m)')\n",
        "ax.set_ylabel('Northing (m)')\n",
        "ax.set_title('NRFA selected station locations')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BvSJGV0B7fJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to play with this try doing all the above but just change the river name."
      ],
      "metadata": {
        "id": "L28kas2YX5Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at a few of your favourite rivers"
      ],
      "metadata": {
        "id": "lxLF24lNi8ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you will test your ability to look at your own favourite river.\n",
        "\n",
        "The steps are:\n",
        "1. Search the catalog for the correct station number.\n",
        "2. Change the station number when getting the data.\n",
        "2. Make the rank column.\n",
        "3. Get the mean annual flood.\n",
        "3. Get the number of years on record from the data.\n",
        "4. Calculate the return period.\n",
        "5. Plot the return period and get the function that describes the flow as a function of return period.\n",
        "6. Calculate the return period of the mean annual flood.\n",
        "7. Get the flow of a big flood (say 500 year).\n"
      ],
      "metadata": {
        "id": "HbECOJ6ujHnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_river = \"Feshie\"\n",
        "stations_data[stations_data['river'].str.contains(my_river)]"
      ],
      "metadata": {
        "id": "InLVmIc3jF32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the station number below."
      ],
      "metadata": {
        "id": "8sicTT-4jljq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nrfapy\n",
        "\n",
        "station = 8013\n",
        "data_type = \"amax-flow\"\n",
        "amax_flow_df = nrfapy.get_ts(station,data_type)\n",
        "amax_flow_df.head()"
      ],
      "metadata": {
        "id": "DO4diKuajit-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the rank column"
      ],
      "metadata": {
        "id": "eW2MZTrKkFSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amax_flow_df['rank_column'] = amax_flow_df['amax-flow'].rank(ascending=False).astype(int)\n",
        "amax_flow_df.head(10)"
      ],
      "metadata": {
        "id": "xSc_U2KDjyQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the number of years on record"
      ],
      "metadata": {
        "id": "E6Ar81vTkHO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_records = len(amax_flow_df['amax-flow'])\n",
        "print(\"The number of years on record is: \"+str(n_records))\n"
      ],
      "metadata": {
        "id": "aMOW2I3ojyQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the mean annual flood"
      ],
      "metadata": {
        "id": "8caaDDSkllwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_amax_Q = amax_flow_df['amax-flow'].mean()\n",
        "median_amax_Q = amax_flow_df['amax-flow'].median()\n",
        "print(\"The mean annual maximum flow is: \" +str(mean_amax_Q) + \" m^3/s and the median is: \" + str(median_amax_Q)+ \" m^3/s\")"
      ],
      "metadata": {
        "id": "c-sAQiO9lncL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the return period"
      ],
      "metadata": {
        "id": "YlXCCxq0kYKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amax_flow_df['return_period'] = (n_records+1)/amax_flow_df['rank_column']\n",
        "amax_flow_df.head(10)"
      ],
      "metadata": {
        "id": "oo0Nlsd8jyQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the fit on the return period"
      ],
      "metadata": {
        "id": "xhKWIcJRkdNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a scatter plot\n",
        "ax = amax_flow_df.plot.scatter(x='return_period', y='amax-flow', figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Return period (yrs)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Return periods for station number: '+str(station))\n",
        "\n",
        "# Set x-axis to logarithmic scale\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Perform a linear regression on the natural log of the x data\n",
        "slope, intercept, r_value, p_value, std_err = linregress(np.log(amax_flow_df['return_period']), amax_flow_df['amax-flow'])\n",
        "\n",
        "# Create a range of x values for the fitted line\n",
        "x_fit = np.linspace(min(amax_flow_df['return_period']), max(amax_flow_df['return_period']), num=500)\n",
        "\n",
        "# Calculate the corresponding y values for the fitted line\n",
        "y_fit = slope * np.log(x_fit) + intercept\n",
        "\n",
        "# Plot the fitted line\n",
        "plt.plot(x_fit, y_fit, 'r', label=f'fit: y = {slope:.2f} * ln(x) + {intercept:.2f}')\n",
        "\n",
        "# Show the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2u1v7w14jyQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_maf = np.exp( (mean_amax_Q - intercept) / slope)\n",
        "print(\"The return period of the mean annual flood is: \"+str(R_maf))"
      ],
      "metadata": {
        "id": "3cC4XQ7rjyQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've set this to the 100 year flood. Don't change it because you will look at the 100 year flood in the next step."
      ],
      "metadata": {
        "id": "b5mZbucOr6Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "big_return_period = 100\n",
        "flood_big = slope*np.log(big_return_period)+ intercept\n",
        "print(\"The discharge of a flood with a return period of \"+str(big_return_period)+ \" years is \"+str(flood_big) + \"m^3/s\")"
      ],
      "metadata": {
        "id": "0CFt4ZI2jyQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Last steps"
      ],
      "metadata": {
        "id": "XaOxxajbFbIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of problem with this form of flood frequency analysis is that it is very sensitive to the number of years on record.  \n",
        "\n",
        "In the next cell, set the station to the same station as above, and select the number of years to remove from the record.\n",
        "\n",
        "Then just run all the cells below and see if the 100 year flood discharge is different."
      ],
      "metadata": {
        "id": "ZteLtevXFvV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years_to_remove = 20\n",
        "station = 8013\n",
        "data_type = \"amax-flow\"\n",
        "amax_flow_df_new = nrfapy.get_ts(station,data_type)\n",
        "amax_flow_df_short = amax_flow_df_new.iloc[:-years_to_remove]\n",
        "amax_flow_df_short['rank_column'] = amax_flow_df_short['amax-flow'].rank(ascending=False).astype(int)\n",
        "n_records = len(amax_flow_df_short['amax-flow'])\n",
        "print(\"The number of years on record is: \"+str(n_records))"
      ],
      "metadata": {
        "id": "taTBNtP7Fur-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amax_flow_df_short['return_period'] = (n_records+1)/amax_flow_df_short['rank_column']\n",
        "amax_flow_df_short.head(10)"
      ],
      "metadata": {
        "id": "r7Vmkf3AHHpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This makes a scatter plot\n",
        "ax = amax_flow_df_short.plot.scatter(x='return_period', y='amax-flow', figsize=(9, 5))\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('Maximum annual flood (m$^3$/s)')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('Return period (yrs)')\n",
        "\n",
        "# Set the title\n",
        "plt.title('Return periods for station number: '+str(station))\n",
        "\n",
        "# Set x-axis to logarithmic scale\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Perform a linear regression on the natural log of the x data\n",
        "sslope, sintercept, sr_value, sp_value, sstd_err = linregress(np.log(amax_flow_df_short['return_period']), amax_flow_df_short['amax-flow'])\n",
        "\n",
        "# Create a range of x values for the fitted line\n",
        "x_fit = np.linspace(min(amax_flow_df_short['return_period']), max(amax_flow_df_short['return_period']), num=500)\n",
        "\n",
        "# Calculate the corresponding y values for the fitted line\n",
        "y_fit = sslope * np.log(x_fit) + sintercept\n",
        "\n",
        "# Plot the fitted line\n",
        "plt.plot(x_fit, y_fit, 'r', label=f'fit: y = {sslope:.2f} * ln(x) + {sintercept:.2f}')\n",
        "\n",
        "# Show the legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Clx1v7g8GlqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_return_period = 100\n",
        "flood_big = sslope*np.log(big_return_period)+ sintercept\n",
        "print(\"The discharge of a flood with a return period of \"+str(big_return_period)+ \" years is \"+str(flood_big) + \"m^3/s\")"
      ],
      "metadata": {
        "id": "IPhEDf7aGv3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I suggest you find a few rivers to test sensitivity to the flow record. What kind of rivers are most sensitive?"
      ],
      "metadata": {
        "id": "8-4KlZc3relE"
      }
    }
  ]
}